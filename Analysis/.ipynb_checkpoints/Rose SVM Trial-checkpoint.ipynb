{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80d12fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## This sets the plot style\n",
    "## to have a grid on a dark background\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9fecfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 5,
=======
   "execution_count": 3,
>>>>>>> Stashed changes
   "id": "ab69a78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in your csv file that has the mid features. \n",
    "\n",
    "\n",
    "data_train = pd.read_csv('../Feature Extraction/midFeaturesTrainSetWithChars')\n",
    "\n",
    "\n",
    "data_test = pd.read_csv('../Feature Extraction/midFeaturesTestSetWithChars')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb50b680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split the data into train and test set, stratified by Emotion.\n",
    "\n",
    "\n",
    "# data_train, data_test = train_test_split(data.copy(),\n",
    "#                                    shuffle=True,\n",
    "#                                    random_state=608,\n",
    "#                                    stratify=data.Emotion,\n",
    "#                                    test_size=0.2\n",
    "#                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c38ae0e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NEU    0.178798\n",
       "HAP    0.164240\n",
       "ANG    0.164240\n",
       "FEA    0.164240\n",
       "DIS    0.164240\n",
       "SAD    0.164240\n",
       "Name: Emotion, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the percentages of the different emotion categories in the training set\n",
    "\n",
    "\n",
    "\n",
    "data_train.Emotion.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2eedfff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NEU    0.179167\n",
       "HAP    0.164167\n",
       "SAD    0.164167\n",
       "FEA    0.164167\n",
       "ANG    0.164167\n",
       "DIS    0.164167\n",
       "Name: Emotion, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the percentages of the different emotion categories in the test set\n",
    "\n",
    "\n",
    "data_test.Emotion.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2b99d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileID</th>\n",
       "      <th>actorID</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>SentenceID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Race</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>energy_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>delta chroma_4_std</th>\n",
       "      <th>delta chroma_5_std</th>\n",
       "      <th>delta chroma_6_std</th>\n",
       "      <th>delta chroma_7_std</th>\n",
       "      <th>delta chroma_8_std</th>\n",
       "      <th>delta chroma_9_std</th>\n",
       "      <th>delta chroma_10_std</th>\n",
       "      <th>delta chroma_11_std</th>\n",
       "      <th>delta chroma_12_std</th>\n",
       "      <th>delta chroma_std_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1091_MTI_HAP_XX</td>\n",
       "      <td>1091</td>\n",
       "      <td>HAP</td>\n",
       "      <td>MTI</td>\n",
       "      <td>29</td>\n",
       "      <td>Female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Not Hispanic</td>\n",
       "      <td>0.103094</td>\n",
       "      <td>0.010426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017033</td>\n",
       "      <td>0.016811</td>\n",
       "      <td>0.018297</td>\n",
       "      <td>0.020554</td>\n",
       "      <td>0.005190</td>\n",
       "      <td>0.008010</td>\n",
       "      <td>0.014288</td>\n",
       "      <td>0.018384</td>\n",
       "      <td>0.003024</td>\n",
       "      <td>0.009549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1033_TIE_NEU_XX</td>\n",
       "      <td>1033</td>\n",
       "      <td>NEU</td>\n",
       "      <td>TIE</td>\n",
       "      <td>31</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Not Hispanic</td>\n",
       "      <td>0.095550</td>\n",
       "      <td>0.006244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026957</td>\n",
       "      <td>0.022260</td>\n",
       "      <td>0.016414</td>\n",
       "      <td>0.016756</td>\n",
       "      <td>0.006733</td>\n",
       "      <td>0.004914</td>\n",
       "      <td>0.014508</td>\n",
       "      <td>0.019974</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.008867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1016_ITH_ANG_XX</td>\n",
       "      <td>1016</td>\n",
       "      <td>ANG</td>\n",
       "      <td>ITH</td>\n",
       "      <td>61</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Not Hispanic</td>\n",
       "      <td>0.084617</td>\n",
       "      <td>0.012109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018824</td>\n",
       "      <td>0.015078</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>0.017400</td>\n",
       "      <td>0.006796</td>\n",
       "      <td>0.004869</td>\n",
       "      <td>0.017074</td>\n",
       "      <td>0.028463</td>\n",
       "      <td>0.006532</td>\n",
       "      <td>0.008469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1082_DFA_NEU_XX</td>\n",
       "      <td>1082</td>\n",
       "      <td>NEU</td>\n",
       "      <td>DFA</td>\n",
       "      <td>20</td>\n",
       "      <td>Female</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Not Hispanic</td>\n",
       "      <td>0.085034</td>\n",
       "      <td>0.006593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018890</td>\n",
       "      <td>0.013363</td>\n",
       "      <td>0.014448</td>\n",
       "      <td>0.019450</td>\n",
       "      <td>0.006658</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>0.021923</td>\n",
       "      <td>0.021861</td>\n",
       "      <td>0.006262</td>\n",
       "      <td>0.008800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1074_ITH_FEA_XX</td>\n",
       "      <td>1074</td>\n",
       "      <td>FEA</td>\n",
       "      <td>ITH</td>\n",
       "      <td>31</td>\n",
       "      <td>Female</td>\n",
       "      <td>African American</td>\n",
       "      <td>Not Hispanic</td>\n",
       "      <td>0.080987</td>\n",
       "      <td>0.009392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032367</td>\n",
       "      <td>0.019901</td>\n",
       "      <td>0.016781</td>\n",
       "      <td>0.019547</td>\n",
       "      <td>0.005369</td>\n",
       "      <td>0.006296</td>\n",
       "      <td>0.014283</td>\n",
       "      <td>0.020008</td>\n",
       "      <td>0.004862</td>\n",
       "      <td>0.008996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 144 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            FileID  actorID Emotion SentenceID  Age     Sex              Race  \\\n",
       "0  1091_MTI_HAP_XX     1091     HAP        MTI   29  Female             Asian   \n",
       "1  1033_TIE_NEU_XX     1033     NEU        TIE   31    Male         Caucasian   \n",
       "2  1016_ITH_ANG_XX     1016     ANG        ITH   61    Male         Caucasian   \n",
       "3  1082_DFA_NEU_XX     1082     NEU        DFA   20  Female         Caucasian   \n",
       "4  1074_ITH_FEA_XX     1074     FEA        ITH   31  Female  African American   \n",
       "\n",
       "      Ethnicity  zcr_mean  energy_mean  ...  delta chroma_4_std  \\\n",
       "0  Not Hispanic  0.103094     0.010426  ...            0.017033   \n",
       "1  Not Hispanic  0.095550     0.006244  ...            0.026957   \n",
       "2  Not Hispanic  0.084617     0.012109  ...            0.018824   \n",
       "3  Not Hispanic  0.085034     0.006593  ...            0.018890   \n",
       "4  Not Hispanic  0.080987     0.009392  ...            0.032367   \n",
       "\n",
       "   delta chroma_5_std  delta chroma_6_std  delta chroma_7_std  \\\n",
       "0            0.016811            0.018297            0.020554   \n",
       "1            0.022260            0.016414            0.016756   \n",
       "2            0.015078            0.014390            0.017400   \n",
       "3            0.013363            0.014448            0.019450   \n",
       "4            0.019901            0.016781            0.019547   \n",
       "\n",
       "   delta chroma_8_std  delta chroma_9_std  delta chroma_10_std  \\\n",
       "0            0.005190            0.008010             0.014288   \n",
       "1            0.006733            0.004914             0.014508   \n",
       "2            0.006796            0.004869             0.017074   \n",
       "3            0.006658            0.007513             0.021923   \n",
       "4            0.005369            0.006296             0.014283   \n",
       "\n",
       "   delta chroma_11_std  delta chroma_12_std  delta chroma_std_std  \n",
       "0             0.018384             0.003024              0.009549  \n",
       "1             0.019974             0.003226              0.008867  \n",
       "2             0.028463             0.006532              0.008469  \n",
       "3             0.021861             0.006262              0.008800  \n",
       "4             0.020008             0.004862              0.008996  \n",
       "\n",
       "[5 rows x 144 columns]"
      ]
     },
<<<<<<< Updated upstream
     "execution_count": 8,
=======
     "execution_count": 3,
>>>>>>> Stashed changes
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c7e8582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train and test set into emotion labels (y), midfeatures (X), and characteristics (char)\n",
    "\n",
    "y_train = data_train[['Emotion']]\n",
    "y_test = data_test[['Emotion']]\n",
    "\n",
    "X_train = data_train.drop(columns = ['FileID', 'actorID', 'Emotion', 'SentenceID', 'Age',\n",
    "                                     'Sex', 'Race', 'Ethnicity'])\n",
    "X_test = data_test.drop(columns = ['FileID', 'actorID', 'Emotion', 'SentenceID', 'Age',\n",
    "                                   'Sex', 'Race', 'Ethnicity' ])\n",
    "\n",
    "char_train = data_train[['SentenceID', 'Age', 'Sex', 'Race', 'Ethnicity']]\n",
    "\n",
<<<<<<< Updated upstream
    "char_test = data_test[['SentenceID', 'Age', 'Sex', 'Race', 'Ethnicity']]\n",
    "\n",
    "\n"
=======
    "data = pd.read_csv('../Feature Extraction/midFeaturesAll.csv')\n",
    "data.head()\n"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 19,
   "id": "7f1c94d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get columns encoding emotions from the y vectors.\n",
    "\n",
    "\n",
    "y_train_dummies = pd.get_dummies(y_train)\n",
    "\n",
    "#y_train = pd.concat([y_train, y_train_dummies], axis=1)\n",
    "\n",
    "y_test_dummies = pd.get_dummies(y_test)\n",
    "\n",
    "#y_test = pd.concat([y_test, y_test_dummies], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e4e933d",
=======
   "execution_count": 4,
   "id": "eb50b680",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get columns encoding characteristics from the char dataframes.\n",
    "\n",
    "char_train_dummies = pd.get_dummies(char_train)\n",
    "\n",
    "char_test_dummies = pd.get_dummies(char_test)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 24,
   "id": "fbd90dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: try to train a support vector machine with Gaussian radial kernel to distinguish between instances\n",
    "# where emotion is 'ANG' and instances where emotion is 'HAP'. \n",
    "\n",
    "\n",
    "\n",
    "# Get the rows of X_train, X_test corresponding to just the emotions 'ANG' and 'HAP'\n",
    "\n",
    "X_train_sub = X_train.loc[(y_train.Emotion == 'ANG') | (y_train.Emotion == 'HAP')]\n",
    "X_test_sub = X_test.loc[(y_test.Emotion == 'ANG') | (y_test.Emotion == 'HAP')]\n",
    "\n",
    "\n",
    "# Get the Emotion_ANG column of the y_dummies, with only the rows corresponding to 'ANG' and 'HAP'\n",
    "\n",
    "y_train_sub = y_train_dummies.loc[(y_train.Emotion == 'ANG') | (y_train.Emotion == 'HAP')].Emotion_ANG\n",
    "y_test_sub = y_test_dummies.loc[(y_test.Emotion == 'ANG') | (y_test.Emotion == 'HAP')].Emotion_ANG\n",
    "\n",
    "\n",
    "# Build pipeline to first scale the mid feature data, then apply the SVC\n",
    "\n",
    "pipe = Pipeline([('scale', StandardScaler()),\n",
    "                 ('svc', SVC(kernel='rbf'))])\n",
    "\n",
    "\n",
    "# Fit the model to the training data\n",
    "\n",
    "pipe.fit(X_train_sub, y_train_sub)\n",
    "\n",
    "    \n",
    "# Get the model's prediction on the test data\n",
    "\n",
    "pred = pipe.predict(X_test_sub)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ad669cd",
=======
   "execution_count": 5,
   "id": "c38ae0e0",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 86, 111],\n",
       "       [ 97, 100]])"
      ]
     },
<<<<<<< Updated upstream
     "execution_count": 25,
=======
     "execution_count": 5,
>>>>>>> Stashed changes
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the confusion matrix for the test data :\n",
    "confusion_matrix(y_test_sub, pred)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 26,
   "id": "35a76ba8",
=======
   "execution_count": 6,
   "id": "f2eedfff",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[661, 140],\n",
       "       [111, 690]])"
      ]
     },
<<<<<<< Updated upstream
     "execution_count": 26,
=======
     "execution_count": 6,
>>>>>>> Stashed changes
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the confusion matrix for the training data:\n",
    "pred_train = pipe.predict(X_train_sub)\n",
    "\n",
    "confusion_matrix(y_train_sub, pred_train)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 28,
   "id": "4df9bb90",
=======
   "execution_count": 7,
   "id": "8c7e8582",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: try to train a support vector machine with Gaussian radial kernel to distinguish between ANG and HAP,\n",
    "# in the subset where the actor is female. \n",
    "\n",
    "\n",
    "# Get the rows of X_train, X_test corresponding to just the emotions 'ANG' and 'HAP'\n",
    "\n",
    "X_train_sub = X_train.loc[(y_train.Emotion == 'ANG') | (y_train.Emotion == 'HAP')]\n",
    "X_test_sub = X_test.loc[(y_test.Emotion == 'ANG') | (y_test.Emotion == 'HAP')]\n",
    "\n",
    "\n",
    "# Get the Emotion_ANG column of the y_dummies, with only the rows corresponding to 'ANG' and 'HAP'\n",
    "\n",
    "y_train_sub = y_train_dummies.loc[(y_train.Emotion == 'ANG') | (y_train.Emotion == 'HAP')].Emotion_ANG\n",
    "y_test_sub = y_test_dummies.loc[(y_test.Emotion == 'ANG') | (y_test.Emotion == 'HAP')].Emotion_ANG\n",
    "\n",
    "\n",
    "# Build pipeline to first scale the mid feature data, then apply the SVC\n",
    "\n",
    "pipe = Pipeline([('scale', StandardScaler()),\n",
    "                 ('svc', SVC(kernel='rbf'))])\n",
    "\n",
    "\n",
    "# Fit the model to the training data\n",
    "\n",
    "pipe.fit(X_train_sub.loc[char_train.Sex == 'Female'], y_train_sub.loc[char_train.Sex == 'Female'])\n",
    "\n",
    "    \n",
    "# Get the model's prediction on the test data\n",
    "\n",
    "pred = pipe.predict(X_test_sub.loc[char_test.Sex == 'Female'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 29,
   "id": "7a67c0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40, 58],\n",
       "       [43, 55]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the confusion matrix for the test data :\n",
    "confusion_matrix(y_test_sub.loc[char_test.Sex == 'Female'], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "adaa3cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4846938775510204"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get accuracy score for the test data:\n",
    "(40+55) / (43+58+40+55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29fe2747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[316,  57],\n",
       "       [ 53, 320]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the confusion matrix for the training data:\n",
    "pred_train = pipe.predict(X_train_sub.loc[char_train.Sex == 'Female'])\n",
    "\n",
    "confusion_matrix(y_train_sub.loc[char_train.Sex == 'Female'], pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f2fe64e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8525469168900804"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get accuracy score for the train data:\n",
    "(316+320) / (53+57+316+320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46d76a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DFA    438\n",
       "IOM    438\n",
       "IWW    438\n",
       "TAI    438\n",
       "TSI    438\n",
       "WSI    438\n",
       "IWL    438\n",
       "TIE    437\n",
       "ITS    437\n",
       "MTI    432\n",
       "ITH    432\n",
       "IEO     73\n",
       "Name: SentenceID, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 3: Train SVM to recognize the difference between sentences 'DFA' and 'IOM'\n",
    "\n",
    "char_train.SentenceID.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "798e06ba",
   "metadata": {},
=======
   "execution_count": 8,
   "id": "7f1c94d5",
   "metadata": {
    "scrolled": true
   },
>>>>>>> Stashed changes
   "outputs": [],
   "source": [
    "# Get the rows of X_train, X_test corresponding to just the sentences 'DFA' and 'IOM'\n",
    "\n",
    "X_train_sub = X_train.loc[(char_train.SentenceID == 'DFA') | (char_train.SentenceID == 'IOM')]\n",
    "X_test_sub = X_test.loc[(char_test.SentenceID == 'DFA') | (char_test.SentenceID == 'IOM')]\n",
    "\n",
    "\n",
    "# Get the SentenceID_DFA column of the char_dummies, with only the rows corresponding to 'DFA' and 'IOM'\n",
    "\n",
    "\n",
    "char_train_sub = char_train_dummies.loc[(char_train.SentenceID == 'DFA') | (char_train.SentenceID == 'IOM')].SentenceID_DFA\n",
    "char_test_sub = char_test_dummies.loc[(char_test.SentenceID == 'DFA') | (char_test.SentenceID == 'IOM')].SentenceID_DFA\n",
    "\n",
    "\n",
    "\n",
    "# Build pipeline to first scale the mid feature data, then apply the SVC\n",
    "\n",
    "pipe = Pipeline([('scale', StandardScaler()),\n",
    "                 ('svc', SVC(kernel='rbf'))])\n",
    "\n",
    "\n",
    "# Fit the model to the training data\n",
    "\n",
    "pipe.fit(X_train_sub, char_train_sub)\n",
    "\n",
    "    \n",
    "# Get the model's prediction on the test data\n",
    "\n",
    "pred = pipe.predict(X_test_sub)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 38,
   "id": "4caeec53",
=======
   "execution_count": 9,
   "id": "6a2275cc",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[45, 63],\n",
       "       [57, 51]])"
      ]
     },
<<<<<<< Updated upstream
     "execution_count": 38,
=======
     "execution_count": 9,
>>>>>>> Stashed changes
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the confusion matrix for the test data :\n",
    "confusion_matrix(char_test_sub, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f89ff61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[370,  68],\n",
       "       [ 59, 379]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the confusion matrix for the training data:\n",
    "pred_train = pipe.predict(X_train_sub)\n",
    "\n",
    "confusion_matrix(char_train_sub, pred_train)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 40,
   "id": "6bf2c87b",
=======
   "execution_count": 10,
   "id": "fbd90dd5",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4: train SVM to distinguish between male and female:\n",
    "\n",
    "# For this example, we just use X_train, X_test. \n",
    "\n",
    "\n",
    "\n",
    "# Get the Sex_Female column of the char_dummies:\n",
    "\n",
    "\n",
    "char_train_sub = char_train_dummies['Sex_Female']\n",
    "char_test_sub = char_test_dummies['Sex_Female']\n",
    "\n",
    "\n",
    "\n",
    "# Build pipeline to first scale the mid feature data, then apply the SVC\n",
    "\n",
    "pipe = Pipeline([('scale', StandardScaler()),\n",
    "                 ('svc', SVC(kernel='rbf'))])\n",
    "\n",
    "\n",
    "# Fit the model to the training data\n",
    "\n",
    "pipe.fit(X_train, char_train_sub)\n",
    "\n",
    "    \n",
    "# Get the model's prediction on the test data\n",
    "\n",
    "pred = pipe.predict(X_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 41,
   "id": "df168dda",
=======
   "execution_count": 11,
   "id": "0ad669cd",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[472, 131],\n",
       "       [480, 117]])"
      ]
     },
<<<<<<< Updated upstream
     "execution_count": 41,
=======
     "execution_count": 11,
>>>>>>> Stashed changes
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the confusion matrix for the test data :\n",
    "confusion_matrix(char_test_sub, pred)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 42,
   "id": "39c064f6",
=======
   "execution_count": 12,
   "id": "35a76ba8",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2444,  163],\n",
       "       [ 938, 1332]])"
      ]
     },
<<<<<<< Updated upstream
     "execution_count": 42,
=======
     "execution_count": 12,
>>>>>>> Stashed changes
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the confusion matrix for the training data:\n",
    "pred_train = pipe.predict(X_train)\n",
    "\n",
    "confusion_matrix(char_train_sub, pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35aa974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a67c0c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
