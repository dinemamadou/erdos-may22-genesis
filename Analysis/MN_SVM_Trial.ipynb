{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80d12fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## This sets the plot style\n",
    "## to have a grid on a dark background\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9fecfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab69a78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4877, 144)\n"
     ]
    }
   ],
   "source": [
    "# Read in your csv file that has the mid features. \n",
    "\n",
    "#data = pd.read_csv('../Feature Extraction/midFeaturesTrainSet.csv')\n",
    "data = pd.read_csv('../../midFeaturesTrainSetWithChars.csv')\n",
    "\n",
    "\n",
    "data.head()\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb50b680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test set, stratified by Emotion.\n",
    "\n",
    "\n",
    "data_train, data_test = train_test_split(data.copy(),\n",
    "                                   shuffle=True,\n",
    "                                   random_state=608,\n",
    "                                   stratify=data.Emotion,\n",
    "                                   test_size=0.2\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e25e4f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileID</th>\n",
       "      <th>actorID</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>SentenceID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Race</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>energy_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>delta chroma_4_std</th>\n",
       "      <th>delta chroma_5_std</th>\n",
       "      <th>delta chroma_6_std</th>\n",
       "      <th>delta chroma_7_std</th>\n",
       "      <th>delta chroma_8_std</th>\n",
       "      <th>delta chroma_9_std</th>\n",
       "      <th>delta chroma_10_std</th>\n",
       "      <th>delta chroma_11_std</th>\n",
       "      <th>delta chroma_12_std</th>\n",
       "      <th>delta chroma_std_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4558</th>\n",
       "      <td>1002_TSI_DIS_XX</td>\n",
       "      <td>1002</td>\n",
       "      <td>DIS</td>\n",
       "      <td>TSI</td>\n",
       "      <td>21</td>\n",
       "      <td>Female</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Not Hispanic</td>\n",
       "      <td>0.063152</td>\n",
       "      <td>0.014035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019344</td>\n",
       "      <td>0.028552</td>\n",
       "      <td>0.008770</td>\n",
       "      <td>0.033243</td>\n",
       "      <td>0.006863</td>\n",
       "      <td>0.010172</td>\n",
       "      <td>0.014090</td>\n",
       "      <td>0.034345</td>\n",
       "      <td>0.007013</td>\n",
       "      <td>0.007990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>1082_MTI_DIS_XX</td>\n",
       "      <td>1082</td>\n",
       "      <td>DIS</td>\n",
       "      <td>MTI</td>\n",
       "      <td>20</td>\n",
       "      <td>Female</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Not Hispanic</td>\n",
       "      <td>0.053911</td>\n",
       "      <td>0.011049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026283</td>\n",
       "      <td>0.028846</td>\n",
       "      <td>0.014705</td>\n",
       "      <td>0.024640</td>\n",
       "      <td>0.004960</td>\n",
       "      <td>0.007395</td>\n",
       "      <td>0.011421</td>\n",
       "      <td>0.019587</td>\n",
       "      <td>0.008811</td>\n",
       "      <td>0.010601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801</th>\n",
       "      <td>1074_TIE_HAP_XX</td>\n",
       "      <td>1074</td>\n",
       "      <td>HAP</td>\n",
       "      <td>TIE</td>\n",
       "      <td>31</td>\n",
       "      <td>Female</td>\n",
       "      <td>African American</td>\n",
       "      <td>Not Hispanic</td>\n",
       "      <td>0.068513</td>\n",
       "      <td>0.014595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022290</td>\n",
       "      <td>0.020090</td>\n",
       "      <td>0.022270</td>\n",
       "      <td>0.036690</td>\n",
       "      <td>0.012071</td>\n",
       "      <td>0.004290</td>\n",
       "      <td>0.019348</td>\n",
       "      <td>0.023656</td>\n",
       "      <td>0.015666</td>\n",
       "      <td>0.008969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2452</th>\n",
       "      <td>1017_IWW_SAD_XX</td>\n",
       "      <td>1017</td>\n",
       "      <td>SAD</td>\n",
       "      <td>IWW</td>\n",
       "      <td>42</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Not Hispanic</td>\n",
       "      <td>0.063355</td>\n",
       "      <td>0.021404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020207</td>\n",
       "      <td>0.016511</td>\n",
       "      <td>0.011392</td>\n",
       "      <td>0.029444</td>\n",
       "      <td>0.007853</td>\n",
       "      <td>0.002882</td>\n",
       "      <td>0.008727</td>\n",
       "      <td>0.028870</td>\n",
       "      <td>0.014876</td>\n",
       "      <td>0.008986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>1044_WSI_NEU_XX</td>\n",
       "      <td>1044</td>\n",
       "      <td>NEU</td>\n",
       "      <td>WSI</td>\n",
       "      <td>40</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Not Hispanic</td>\n",
       "      <td>0.070894</td>\n",
       "      <td>0.014864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027933</td>\n",
       "      <td>0.016130</td>\n",
       "      <td>0.012093</td>\n",
       "      <td>0.030013</td>\n",
       "      <td>0.004832</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.008814</td>\n",
       "      <td>0.027979</td>\n",
       "      <td>0.004611</td>\n",
       "      <td>0.009570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 144 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               FileID  actorID Emotion SentenceID  Age     Sex  \\\n",
       "4558  1002_TSI_DIS_XX     1002     DIS        TSI   21  Female   \n",
       "837   1082_MTI_DIS_XX     1082     DIS        MTI   20  Female   \n",
       "1801  1074_TIE_HAP_XX     1074     HAP        TIE   31  Female   \n",
       "2452  1017_IWW_SAD_XX     1017     SAD        IWW   42    Male   \n",
       "2494  1044_WSI_NEU_XX     1044     NEU        WSI   40    Male   \n",
       "\n",
       "                  Race     Ethnicity  zcr_mean  energy_mean  ...  \\\n",
       "4558         Caucasian  Not Hispanic  0.063152     0.014035  ...   \n",
       "837          Caucasian  Not Hispanic  0.053911     0.011049  ...   \n",
       "1801  African American  Not Hispanic  0.068513     0.014595  ...   \n",
       "2452         Caucasian  Not Hispanic  0.063355     0.021404  ...   \n",
       "2494         Caucasian  Not Hispanic  0.070894     0.014864  ...   \n",
       "\n",
       "      delta chroma_4_std  delta chroma_5_std  delta chroma_6_std  \\\n",
       "4558            0.019344            0.028552            0.008770   \n",
       "837             0.026283            0.028846            0.014705   \n",
       "1801            0.022290            0.020090            0.022270   \n",
       "2452            0.020207            0.016511            0.011392   \n",
       "2494            0.027933            0.016130            0.012093   \n",
       "\n",
       "      delta chroma_7_std  delta chroma_8_std  delta chroma_9_std  \\\n",
       "4558            0.033243            0.006863            0.010172   \n",
       "837             0.024640            0.004960            0.007395   \n",
       "1801            0.036690            0.012071            0.004290   \n",
       "2452            0.029444            0.007853            0.002882   \n",
       "2494            0.030013            0.004832            0.005100   \n",
       "\n",
       "      delta chroma_10_std  delta chroma_11_std  delta chroma_12_std  \\\n",
       "4558             0.014090             0.034345             0.007013   \n",
       "837              0.011421             0.019587             0.008811   \n",
       "1801             0.019348             0.023656             0.015666   \n",
       "2452             0.008727             0.028870             0.014876   \n",
       "2494             0.008814             0.027979             0.004611   \n",
       "\n",
       "      delta chroma_std_std  \n",
       "4558              0.007990  \n",
       "837               0.010601  \n",
       "1801              0.008969  \n",
       "2452              0.008986  \n",
       "2494              0.009570  \n",
       "\n",
       "[5 rows x 144 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c38ae0e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NEU    0.178672\n",
       "SAD    0.164317\n",
       "HAP    0.164317\n",
       "DIS    0.164317\n",
       "FEA    0.164317\n",
       "ANG    0.164060\n",
       "Name: Emotion, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the percentages of the different emotion categories in the training set\n",
    "\n",
    "\n",
    "\n",
    "data_train.Emotion.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f2eedfff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NEU    0.179303\n",
       "ANG    0.164959\n",
       "DIS    0.163934\n",
       "SAD    0.163934\n",
       "HAP    0.163934\n",
       "FEA    0.163934\n",
       "Name: Emotion, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the percentages of the different emotion categories in the test set\n",
    "\n",
    "data_test.Emotion.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "20b917cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the train and test(validataion) set based on the sentences \n",
    "\n",
    "# IEO - It's 11 o'clock.\n",
    "# TIE - That is exactly what happend.\n",
    "# IOM - I'm on my way to the meeting.\n",
    "# IWW - I wonder what this is about.\n",
    "# TAI - The airplane is almost full.\n",
    "# MTI - Maybe tomorrow it will be cold.\n",
    "# IWL - I would like a new alarm clock.\n",
    "# ITH - I think I have a doctor's appointment.\n",
    "# DFA - Dont forget a jacket.\n",
    "# ITS - I think I've seen this before.\n",
    "# TSI - The surface is slick.\n",
    "# WSI - We'll stop in a couple of minutes.\n",
    "\n",
    "# Get the rows of X_train, X_test corresponding to specific sentences\n",
    "\n",
    "# Split the train and test set into labels (y) and features (X)\n",
    "\n",
    "y_train = data_train[['Emotion']]\n",
    "y_test  = data_test[['Emotion']]\n",
    "\n",
    "X_train = data_train.drop(columns  = ['actorID', 'Emotion', 'SentenceID', 'Age', 'Race', 'Ethnicity'])\n",
    "X_test  = data_test.drop(columns   = ['actorID', 'Emotion', 'SentenceID', 'Age', 'Race', 'Ethnicity'])\n",
    "\n",
    "\n",
    "#X_train = data_train.drop(columns  = ['ActorID', 'Emotion', 'SentenceID'])\n",
    "#X_test  = data_test.drop(columns   = ['ActorID', 'Emotion', 'SentenceID'])\n",
    "\n",
    "\n",
    "X_train = data_train[['FileID','energy_mean','Sex']]\n",
    "X_test  = data_test[['FileID','energy_mean','Sex']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8239ce50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the train and test(validataion) set based on the sentences \n",
    "\n",
    "# IEO - It's 11 o'clock.\n",
    "# TIE - That is exactly what happend.\n",
    "# IOM - I'm on my way to the meeting.\n",
    "# IWW - I wonder what this is about.\n",
    "# TAI - The airplane is almost full.\n",
    "# MTI - Maybe tomorrow it will be cold.\n",
    "# IWL - I would like a new alarm clock.\n",
    "# ITH - I think I have a doctor's appointment.\n",
    "# DFA - Dont forget a jacket.\n",
    "# ITS - I think I've seen this before.\n",
    "# TSI - The surface is slick.\n",
    "# WSI - We'll stop in a couple of minutes.\n",
    "\n",
    "\n",
    "X_train.FileID = X_train[\"FileID\"].str[5:8]\n",
    "X_test.FileID  = X_test[\"FileID\"].str[5:8]\n",
    "\n",
    "################################################\n",
    "#X_train_sen = X_train.loc[(X_train.FileID == 'IOE') | (X_train.FileID == 'TIE') | (X_train.FileID == 'MTI') | (X_train.FileID == 'DFA')]\n",
    "#X_test_sen  = X_test.loc[(X_test.FileID == 'IOE') | (X_test.FileID == 'TIE') | (X_test.FileID == 'MTI') | (X_train.FileID == 'DFA')]\n",
    "\n",
    "#y_train_sen = y_train.loc[(X_train.FileID == 'IOE') | (X_train.FileID == 'TIE') | (X_train.FileID == 'MTI') | (X_train.FileID == 'DFA')]\n",
    "#y_test_sen  = y_test.loc[(X_test.FileID == 'IOE') | (X_test.FileID == 'TIE') | (X_test.FileID == 'MTI') | (X_train.FileID == 'DFA')]\n",
    "\n",
    "#################################################\n",
    "#X_train_sen = X_train.loc[(X_train.FileID == 'IWW') | (X_train.FileID == 'ITH') | (X_train.FileID == 'ITS')]\n",
    "#X_test_sen  = X_test.loc[(X_test.FileID == 'IWW') | (X_test.FileID == 'ITH') | (X_test.FileID == 'ITS')]\n",
    "\n",
    "#y_train_sen = y_train.loc[(X_train.FileID == 'IWW') | (X_train.FileID == 'ITH') | (X_train.FileID == 'ITS')]\n",
    "#y_test_sen  = y_test.loc[(X_test.FileID == 'IWW') | (X_test.FileID == 'ITH') | (X_test.FileID == 'ITS')]\n",
    "\n",
    "#################################################\n",
    "#X_train_sen = X_train.loc[(X_train.FileID == 'TAI') | (X_train.FileID == 'IWL') | (X_train.FileID == 'IOM') | (X_train.FileID == 'TSI') | (X_train.FileID == 'WSI')]\n",
    "#X_test_sen  = X_test.loc[(X_test.FileID == 'TAI') | (X_test.FileID == 'IWL') | (X_test.FileID == 'IOM') | (X_train.FileID == 'TSI') | (X_train.FileID == 'WSI')]\n",
    "\n",
    "#y_train_sen = y_train.loc[(X_train.FileID == 'TAI') | (X_train.FileID == 'IWL') | (X_train.FileID == 'IOM') | (X_train.FileID == 'TSI') | (X_train.FileID == 'WSI')]\n",
    "#y_test_sen  = y_test.loc[(X_test.FileID == 'TAI') | (X_test.FileID == 'IWL') | (X_test.FileID == 'IOM') | (X_train.FileID == 'TSI') | (X_train.FileID == 'WSI')]\n",
    "\n",
    "##################################################\n",
    "\n",
    "#X_train_sen1 = X_train.loc[(X_train.FileID == 'IWW') | (X_train.FileID == 'ITH') | (X_train.FileID == 'ITS')]\n",
    "#X_test_sen1  = X_test.loc[(X_test.FileID == 'IWW') | (X_test.FileID == 'ITH') | (X_test.FileID == 'ITS')]\n",
    "\n",
    "#y_train_sen1 = y_train.loc[(X_train.FileID == 'IWW') | (X_train.FileID == 'ITH') | (X_train.FileID == 'ITS')]\n",
    "#y_test_sen1  = y_test.loc[(X_test.FileID == 'IWW') | (X_test.FileID == 'ITH') | (X_test.FileID == 'ITS')]\n",
    "\n",
    "#X_train_sen = X_train_sen.loc[(X_train.Sex == 'Male')]\n",
    "#X_test_sen  = X_test_sen.loc[(X_test.Sex == 'Male')]\n",
    "\n",
    "#y_train_sen = y_train_sen.loc[(X_train.Sex == 'Male')]\n",
    "#y_test_sen  = y_test_sen.loc[(X_test.Sex == 'Male')]\n",
    "\n",
    "\n",
    "\n",
    "X_train_sen1 = X_train\n",
    "X_test_sen1  = X_test\n",
    "\n",
    "y_train_sen1 = y_train\n",
    "y_test_sen1 = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5857ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sen = X_train_sen1.loc[(X_train.Sex == 'Male')]\n",
    "X_test_sen  = X_test_sen1.loc[(X_test.Sex == 'Male')]\n",
    "\n",
    "y_train_sen = y_train_sen1.loc[(X_train.Sex == 'Male')]\n",
    "y_test_sen  = y_test_sen1.loc[(X_test.Sex == 'Male')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1f50f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3831</th>\n",
       "      <td>SAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4372</th>\n",
       "      <td>SAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3061</th>\n",
       "      <td>DIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>FEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4037</th>\n",
       "      <td>SAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>DIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>FEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4188</th>\n",
       "      <td>ANG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3857</th>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3493</th>\n",
       "      <td>ANG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2072 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Emotion\n",
       "3831     SAD\n",
       "4372     SAD\n",
       "3061     DIS\n",
       "1528     FEA\n",
       "4037     SAD\n",
       "...      ...\n",
       "233      DIS\n",
       "333      FEA\n",
       "4188     ANG\n",
       "3857     NEU\n",
       "3493     ANG\n",
       "\n",
       "[2072 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19680db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sen = X_train_sen.drop(columns = ['FileID','Sex'])\n",
    "X_test_sen  = X_test_sen.drop(columns = ['FileID','Sex'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f1c94d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add a column to the y vectors encoding each of the emotions.\n",
    "\n",
    "y_train_sen_dummies = pd.get_dummies(y_train_sen)\n",
    "y_train_sen         = pd.concat([y_train_sen, y_train_sen_dummies], axis=1)\n",
    "\n",
    "y_test_sen_dummies  = pd.get_dummies(y_test)\n",
    "y_test_sen          = pd.concat([y_test_sen, y_test_sen_dummies], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a2275cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3831</th>\n",
       "      <td>0.019216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4372</th>\n",
       "      <td>0.005302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3061</th>\n",
       "      <td>0.007254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>0.072522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4037</th>\n",
       "      <td>0.026553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>0.023722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>0.017539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4188</th>\n",
       "      <td>0.018437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3857</th>\n",
       "      <td>0.014280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3493</th>\n",
       "      <td>0.019385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2072 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      energy_mean\n",
       "3831     0.019216\n",
       "4372     0.005302\n",
       "3061     0.007254\n",
       "1528     0.072522\n",
       "4037     0.026553\n",
       "...           ...\n",
       "233      0.023722\n",
       "333      0.017539\n",
       "4188     0.018437\n",
       "3857     0.014280\n",
       "3493     0.019385\n",
       "\n",
       "[2072 rows x 1 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the encoding looks right\n",
    "\n",
    "X_train_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a83d9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3674    NEU\n",
       "3292    NEU\n",
       "4808    NEU\n",
       "418     NEU\n",
       "649     NEU\n",
       "       ... \n",
       "1423    NEU\n",
       "3882    NEU\n",
       "170     NEU\n",
       "3816    NEU\n",
       "3857    NEU\n",
       "Name: Emotion, Length: 363, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_sen.Emotion[y_train_sen.Emotion == 'NEU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a85f1dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: try to train a support vector machine with Gaussian radial kernel to distinguish between instances\n",
    "# where emotion is 'ANG' and instances where emotion is 'HAP'. \n",
    "\n",
    "# Get the rows of X_train, X_test corresponding to just the emotions 'ANG' and 'HAP'\n",
    "\n",
    "X_train_sub = X_train_sen.loc[(y_train_sen.Emotion == 'HAP') | (y_train_sen.Emotion == 'NEU')]\n",
    "X_test_sub  = X_test_sen.loc[(y_test_sen.Emotion == 'HAP') | (y_test_sen.Emotion == 'NEU')]\n",
    "\n",
    "\n",
    "# Get the Emotion_ANG column of the ys, with only the rows corresponding to 'ANG' and 'HAP'\n",
    "\n",
    "y_train_sub = y_train_sen.loc[(y_train_sen.Emotion == 'HAP') | (y_train_sen.Emotion == 'NEU')].Emotion_HAP\n",
    "y_test_sub = y_test_sen.loc[(y_test_sen.Emotion == 'HAP') | (y_test_sen.Emotion == 'NEU')].Emotion_HAP\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b79e1204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_sub (705, 1)\n",
      "y_train_sub (705,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train_sub\",  X_train_sub.shape)\n",
    "print(\"y_train_sub\",  y_train_sub.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80c46759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=uint8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fce1540d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build pipeline to first scale the mid feature data, then apply the SVC\n",
    "\n",
    "pipe = Pipeline([('scale', StandardScaler()),\n",
    "                 ('svc', SVC(kernel='rbf'))])\n",
    "\n",
    "\n",
    "# Fit the model to the training data\n",
    "\n",
    "pipe.fit(X_train_sub, y_train_sub)\n",
    "\n",
    "    \n",
    "# Get the model's prediction on the test data\n",
    "\n",
    "pred = pipe.predict(X_test_sub)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d707f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build pipeline to first scale the mid feature data, then apply the SVC\n",
    "\n",
    "pipe = Pipeline([('scale', StandardScaler()),\n",
    "                 ('svc', SVC(kernel='rbf'))])\n",
    "\n",
    "\n",
    "# Fit the model t#o the training data\n",
    "\n",
    "pipe.fit(X_train_sub, y_train_sub)\n",
    "\n",
    "    \n",
    "# Get the model's prediction on the test data\n",
    "\n",
    "pred = pipe.predict(X_test_sub)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ad669cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix for the test set is:\n",
      "[[77 27]\n",
      " [59 27]]\n",
      "\n",
      "confusion matrix for the train set is:\n",
      "[[256 107]\n",
      " [219 123]]\n"
     ]
    }
   ],
   "source": [
    "# Look at the confusion matrix for the test data :\n",
    "\n",
    "print(\"confusion matrix for the test set is:\")\n",
    "print(confusion_matrix(y_test_sub, pred))\n",
    "print()\n",
    "\n",
    "# Look at the confusion matrix for the training data:\n",
    "pred_train = pipe.predict(X_train_sub)\n",
    "print(\"confusion matrix for the train set is:\")\n",
    "print(confusion_matrix(y_train_sub, pred_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9f04ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5d7866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945b427d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
