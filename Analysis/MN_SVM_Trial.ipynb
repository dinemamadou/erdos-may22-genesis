{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80d12fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## This sets the plot style\n",
    "## to have a grid on a dark background\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9fecfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab69a78e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileID</th>\n",
       "      <th>actorID</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>SentenceID</th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>energy_mean</th>\n",
       "      <th>energy_entropy_mean</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_spread_mean</th>\n",
       "      <th>spectral_entropy_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>delta chroma_4_std</th>\n",
       "      <th>delta chroma_5_std</th>\n",
       "      <th>delta chroma_6_std</th>\n",
       "      <th>delta chroma_7_std</th>\n",
       "      <th>delta chroma_8_std</th>\n",
       "      <th>delta chroma_9_std</th>\n",
       "      <th>delta chroma_10_std</th>\n",
       "      <th>delta chroma_11_std</th>\n",
       "      <th>delta chroma_12_std</th>\n",
       "      <th>delta chroma_std_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1022_ITS_ANG_XX</td>\n",
       "      <td>1022</td>\n",
       "      <td>ANG</td>\n",
       "      <td>ITS</td>\n",
       "      <td>0.103094</td>\n",
       "      <td>0.010426</td>\n",
       "      <td>2.965602</td>\n",
       "      <td>0.200915</td>\n",
       "      <td>0.226480</td>\n",
       "      <td>0.772772</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017033</td>\n",
       "      <td>0.016811</td>\n",
       "      <td>0.018297</td>\n",
       "      <td>0.020554</td>\n",
       "      <td>0.005190</td>\n",
       "      <td>0.008010</td>\n",
       "      <td>0.014288</td>\n",
       "      <td>0.018384</td>\n",
       "      <td>0.003024</td>\n",
       "      <td>0.009549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1037_ITS_ANG_XX</td>\n",
       "      <td>1037</td>\n",
       "      <td>ANG</td>\n",
       "      <td>ITS</td>\n",
       "      <td>0.095550</td>\n",
       "      <td>0.006244</td>\n",
       "      <td>3.041436</td>\n",
       "      <td>0.196182</td>\n",
       "      <td>0.225279</td>\n",
       "      <td>0.734872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026957</td>\n",
       "      <td>0.022260</td>\n",
       "      <td>0.016414</td>\n",
       "      <td>0.016756</td>\n",
       "      <td>0.006733</td>\n",
       "      <td>0.004914</td>\n",
       "      <td>0.014508</td>\n",
       "      <td>0.019974</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.008867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1060_ITS_NEU_XX</td>\n",
       "      <td>1060</td>\n",
       "      <td>NEU</td>\n",
       "      <td>ITS</td>\n",
       "      <td>0.084617</td>\n",
       "      <td>0.012109</td>\n",
       "      <td>3.013764</td>\n",
       "      <td>0.187499</td>\n",
       "      <td>0.225614</td>\n",
       "      <td>0.616980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018824</td>\n",
       "      <td>0.015078</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>0.017400</td>\n",
       "      <td>0.006796</td>\n",
       "      <td>0.004869</td>\n",
       "      <td>0.017074</td>\n",
       "      <td>0.028463</td>\n",
       "      <td>0.006532</td>\n",
       "      <td>0.008469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1075_ITS_NEU_XX</td>\n",
       "      <td>1075</td>\n",
       "      <td>NEU</td>\n",
       "      <td>ITS</td>\n",
       "      <td>0.085034</td>\n",
       "      <td>0.006593</td>\n",
       "      <td>3.017314</td>\n",
       "      <td>0.196016</td>\n",
       "      <td>0.226223</td>\n",
       "      <td>0.645377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018890</td>\n",
       "      <td>0.013363</td>\n",
       "      <td>0.014448</td>\n",
       "      <td>0.019450</td>\n",
       "      <td>0.006658</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>0.021923</td>\n",
       "      <td>0.021861</td>\n",
       "      <td>0.006262</td>\n",
       "      <td>0.008800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1073_IOM_DIS_XX</td>\n",
       "      <td>1073</td>\n",
       "      <td>DIS</td>\n",
       "      <td>IOM</td>\n",
       "      <td>0.080987</td>\n",
       "      <td>0.009392</td>\n",
       "      <td>3.016705</td>\n",
       "      <td>0.187943</td>\n",
       "      <td>0.220785</td>\n",
       "      <td>0.622735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032367</td>\n",
       "      <td>0.019901</td>\n",
       "      <td>0.016781</td>\n",
       "      <td>0.019547</td>\n",
       "      <td>0.005369</td>\n",
       "      <td>0.006296</td>\n",
       "      <td>0.014283</td>\n",
       "      <td>0.020008</td>\n",
       "      <td>0.004862</td>\n",
       "      <td>0.008996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            FileID  actorID Emotion SentenceID  zcr_mean  energy_mean  \\\n",
       "0  1022_ITS_ANG_XX     1022     ANG        ITS  0.103094     0.010426   \n",
       "1  1037_ITS_ANG_XX     1037     ANG        ITS  0.095550     0.006244   \n",
       "2  1060_ITS_NEU_XX     1060     NEU        ITS  0.084617     0.012109   \n",
       "3  1075_ITS_NEU_XX     1075     NEU        ITS  0.085034     0.006593   \n",
       "4  1073_IOM_DIS_XX     1073     DIS        IOM  0.080987     0.009392   \n",
       "\n",
       "   energy_entropy_mean  spectral_centroid_mean  spectral_spread_mean  \\\n",
       "0             2.965602                0.200915              0.226480   \n",
       "1             3.041436                0.196182              0.225279   \n",
       "2             3.013764                0.187499              0.225614   \n",
       "3             3.017314                0.196016              0.226223   \n",
       "4             3.016705                0.187943              0.220785   \n",
       "\n",
       "   spectral_entropy_mean  ...  delta chroma_4_std  delta chroma_5_std  \\\n",
       "0               0.772772  ...            0.017033            0.016811   \n",
       "1               0.734872  ...            0.026957            0.022260   \n",
       "2               0.616980  ...            0.018824            0.015078   \n",
       "3               0.645377  ...            0.018890            0.013363   \n",
       "4               0.622735  ...            0.032367            0.019901   \n",
       "\n",
       "   delta chroma_6_std  delta chroma_7_std  delta chroma_8_std  \\\n",
       "0            0.018297            0.020554            0.005190   \n",
       "1            0.016414            0.016756            0.006733   \n",
       "2            0.014390            0.017400            0.006796   \n",
       "3            0.014448            0.019450            0.006658   \n",
       "4            0.016781            0.019547            0.005369   \n",
       "\n",
       "   delta chroma_9_std  delta chroma_10_std  delta chroma_11_std  \\\n",
       "0            0.008010             0.014288             0.018384   \n",
       "1            0.004914             0.014508             0.019974   \n",
       "2            0.004869             0.017074             0.028463   \n",
       "3            0.007513             0.021923             0.021861   \n",
       "4            0.006296             0.014283             0.020008   \n",
       "\n",
       "   delta chroma_12_std  delta chroma_std_std  \n",
       "0             0.003024              0.009549  \n",
       "1             0.003226              0.008867  \n",
       "2             0.006532              0.008469  \n",
       "3             0.006262              0.008800  \n",
       "4             0.004862              0.008996  \n",
       "\n",
       "[5 rows x 140 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in your csv file that has the mid features. \n",
    "\n",
    "\n",
    "data = pd.read_csv('../Feature Extraction/midFeaturesAll.csv')\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb50b680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test set, stratified by Emotion.\n",
    "\n",
    "\n",
    "data_train, data_test = train_test_split(data.copy(),\n",
    "                                   shuffle=True,\n",
    "                                   random_state=608,\n",
    "                                   stratify=data.Emotion,\n",
    "                                   test_size=0.2\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c38ae0e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SAD    0.170838\n",
       "DIS    0.170838\n",
       "FEA    0.170838\n",
       "HAP    0.170838\n",
       "ANG    0.170670\n",
       "NEU    0.145977\n",
       "Name: Emotion, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the percentages of the different emotion categories in the training set\n",
    "\n",
    "\n",
    "\n",
    "data_train.Emotion.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2eedfff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ANG    0.171256\n",
       "HAP    0.170584\n",
       "DIS    0.170584\n",
       "FEA    0.170584\n",
       "SAD    0.170584\n",
       "NEU    0.146407\n",
       "Name: Emotion, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the percentages of the different emotion categories in the test set\n",
    "\n",
    "\n",
    "data_test.Emotion.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c7e8582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train and test set into labels (y) and features (X)\n",
    "\n",
    "y_train = data_train[['Emotion']]\n",
    "y_test = data_test[['Emotion']]\n",
    "\n",
    "X_train = data_train.drop(columns = ['FileID', 'actorID', 'Emotion', 'SentenceID' ])\n",
    "X_test = data_test.drop(columns = ['FileID', 'actorID', 'Emotion', 'SentenceID' ])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f1c94d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add a column to the y vectors encoding each of the emotions.\n",
    "\n",
    "\n",
    "y_train_dummies = pd.get_dummies(y_train)\n",
    "\n",
    "y_train = pd.concat([y_train, y_train_dummies], axis=1)\n",
    "\n",
    "y_test_dummies = pd.get_dummies(y_test)\n",
    "\n",
    "y_test = pd.concat([y_test, y_test_dummies], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a2275cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Emotion_ANG</th>\n",
       "      <th>Emotion_DIS</th>\n",
       "      <th>Emotion_FEA</th>\n",
       "      <th>Emotion_HAP</th>\n",
       "      <th>Emotion_NEU</th>\n",
       "      <th>Emotion_SAD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3771</th>\n",
       "      <td>SAD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2809</th>\n",
       "      <td>DIS</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7041</th>\n",
       "      <td>FEA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>NEU</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3342</th>\n",
       "      <td>SAD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Emotion  Emotion_ANG  Emotion_DIS  Emotion_FEA  Emotion_HAP  Emotion_NEU  \\\n",
       "3771     SAD            0            0            0            0            0   \n",
       "2809     DIS            0            1            0            0            0   \n",
       "7041     FEA            0            0            1            0            0   \n",
       "2129     NEU            0            0            0            0            1   \n",
       "3342     SAD            0            0            0            0            0   \n",
       "\n",
       "      Emotion_SAD  \n",
       "3771            1  \n",
       "2809            0  \n",
       "7041            0  \n",
       "2129            0  \n",
       "3342            1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the encoding looks right\n",
    "\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbd90dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: try to train a support vector machine with Gaussian radial kernel to distinguish between instances\n",
    "# where emotion is 'ANG' and instances where emotion is 'HAP'. \n",
    "\n",
    "\n",
    "\n",
    "# Get the rows of X_train, X_test corresponding to just the emotions 'ANG' and 'HAP'\n",
    "\n",
    "X_train_sub = X_train.loc[(y_train.Emotion == 'ANG') | (y_train.Emotion == 'HAP')]\n",
    "X_test_sub = X_test.loc[(y_test.Emotion == 'ANG') | (y_test.Emotion == 'HAP')]\n",
    "\n",
    "\n",
    "# Get the Emotion_ANG column of the ys, with only the rows corresponding to 'ANG' and 'HAP'\n",
    "\n",
    "y_train_sub = y_train.loc[(y_train.Emotion == 'ANG') | (y_train.Emotion == 'HAP')].Emotion_ANG\n",
    "y_test_sub = y_test.loc[(y_test.Emotion == 'ANG') | (y_test.Emotion == 'HAP')].Emotion_ANG\n",
    "\n",
    "\n",
    "# Build pipeline to first scale the mid feature data, then apply the SVC\n",
    "\n",
    "pipe = Pipeline([('scale', StandardScaler()),\n",
    "                 ('svc', SVC(kernel='rbf'))])\n",
    "\n",
    "\n",
    "# Fit the model to the training data\n",
    "\n",
    "pipe.fit(X_train_sub, y_train_sub)\n",
    "\n",
    "    \n",
    "# Get the model's prediction on the test data\n",
    "\n",
    "pred = pipe.predict(X_test_sub)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ad669cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[126, 128],\n",
       "       [129, 126]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the confusion matrix for the test data :\n",
    "confusion_matrix(y_test_sub, pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35a76ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[859, 158],\n",
       "       [188, 828]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the confusion matrix for the training data:\n",
    "pred_train = pipe.predict(X_train_sub)\n",
    "\n",
    "confusion_matrix(y_train_sub, pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df9bb90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a67c0c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
