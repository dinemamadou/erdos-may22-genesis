{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43db7f1e",
   "metadata": {},
   "source": [
    "In this file, we load the actor characteristics \"age\", \"sex\", \"race\", and \"ethnicity\" into the data files for the mid features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bf9229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyAudioAnalysis import ShortTermFeatures as aF\n",
    "from pyAudioAnalysis import audioBasicIO as aIO \n",
    "from pyAudioAnalysis import MidTermFeatures as mF\n",
    "import numpy as np \n",
    "import plotly.graph_objs as go \n",
    "import plotly\n",
    "import IPython\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os, shutil\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dadb4dcf",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../VideoDemographics.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_960160/4011595053.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mactor_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../VideoDemographics.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pyAudioAnalysis/../pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pyAudioAnalysis/../pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pyAudioAnalysis/../pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pyAudioAnalysis/../pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pyAudioAnalysis/../pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pyAudioAnalysis/../pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pyAudioAnalysis/../pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pyAudioAnalysis/../pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../VideoDemographics.csv'"
     ]
    }
   ],
   "source": [
    "# Load the file that contains actor ids and characteristics\n",
    "\n",
    "\n",
    "actor_data = pd.read_csv('../../VideoDemographics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d314e424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the mid term features data for the training and test sets\n",
    "\n",
    "\n",
    "mid_data_train = pd.read_csv('midFeaturesTrainSet.csv')\n",
    "mid_data_test = pd.read_csv('midFeaturesTestSet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baf658fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'actor_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_960160/844735175.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactor_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mactor_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactor_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ActorID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mactor_age\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactor_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Age'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'actor_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Use actor_data to make dicts mapping actor id to characteristics\n",
    "\n",
    "\n",
    "age_dict = {}\n",
    "sex_dict = {}\n",
    "race_dict = {}\n",
    "ethnicity_dict = {}\n",
    "\n",
    "\n",
    "\n",
    "for i in actor_data.index:\n",
    "    actor_id = actor_data.at[i, 'ActorID']\n",
    "    actor_age = actor_data.at[i, 'Age']\n",
    "    actor_sex = actor_data.at[i, 'Sex']\n",
    "    actor_race = actor_data.at[i, 'Race']\n",
    "    actor_ethnicity = actor_data.at[i, 'Ethnicity']\n",
    "    age_dict[actor_id] = actor_age\n",
    "    sex_dict[actor_id] = actor_sex\n",
    "    race_dict[actor_id] = actor_race\n",
    "    ethnicity_dict[actor_id] = actor_ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01d3336a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mid_data_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_960160/713433203.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmid_data_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mage_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmid_data_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'actorID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mage_list_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mid_data_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Get lists of characteristics in the order actors appear in mid_data_train:\n",
    "\n",
    "\n",
    "age_list_train = []\n",
    "sex_list_train = []\n",
    "race_list_train = []\n",
    "ethnicity_list_train = []\n",
    "\n",
    "\n",
    "for j in mid_data_train.index:\n",
    "    age = age_dict[mid_data_train.at[j, 'ActorID']]\n",
    "    age_list_train.append(age)\n",
    "    \n",
    "    sex = sex_dict[mid_data_train.at[j, 'ActorID']]\n",
    "    sex_list_train.append(sex)\n",
    "    \n",
    "    race = race_dict[mid_data_train.at[j, 'ActorID']]\n",
    "    race_list_train.append(race)\n",
    "    \n",
    "    ethnicity = ethnicity_dict[mid_data_train.at[j, 'ActorID']]\n",
    "    ethnicity_list_train.append(ethnicity)\n",
    "    \n",
    "# Get lists of characteristics in the order actors appear in mid_data_test:\n",
    "\n",
    "age_list_test = []\n",
    "sex_list_test = []\n",
    "race_list_test = []\n",
    "ethnicity_list_test = []\n",
    "\n",
    "\n",
    "for j in mid_data_test.index:\n",
    "    age = age_dict[mid_data_test.at[j, 'ActorID']]\n",
    "    age_list_test.append(age)\n",
    "    \n",
    "    sex = sex_dict[mid_data_test.at[j, 'ActorID']]\n",
    "    sex_list_test.append(sex)\n",
    "    \n",
    "    race = race_dict[mid_data_test.at[j, 'ActorID']]\n",
    "    race_list_test.append(race)\n",
    "    \n",
    "    ethnicity = ethnicity_dict[mid_data_test.at[j, 'ActorID']]\n",
    "    ethnicity_list_test.append(ethnicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97337e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the characteristics columns to mid_data_train:\n",
    "\n",
    "\n",
    "mid_data_train.insert(4, 'Age', age_list_train)\n",
    "mid_data_train.insert(5, 'Sex', sex_list_train)\n",
    "mid_data_train.insert(6, 'Race', race_list_train)\n",
    "mid_data_train.insert(7, 'Ethnicity', ethnicity_list_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "055f21d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileID</th>\n",
       "      <th>ActorID</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>SentenceID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Race</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>energy_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>delta chroma_4_std</th>\n",
       "      <th>delta chroma_5_std</th>\n",
       "      <th>delta chroma_6_std</th>\n",
       "      <th>delta chroma_7_std</th>\n",
       "      <th>delta chroma_8_std</th>\n",
       "      <th>delta chroma_9_std</th>\n",
       "      <th>delta chroma_10_std</th>\n",
       "      <th>delta chroma_11_std</th>\n",
       "      <th>delta chroma_12_std</th>\n",
       "      <th>delta chroma_std_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1091_MTI_HAP_XX</td>\n",
       "      <td>1091</td>\n",
       "      <td>HAP</td>\n",
       "      <td>MTI</td>\n",
       "      <td>29</td>\n",
       "      <td>Female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Not Hispanic</td>\n",
       "      <td>0.103094</td>\n",
       "      <td>0.010426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017033</td>\n",
       "      <td>0.016811</td>\n",
       "      <td>0.018297</td>\n",
       "      <td>0.020554</td>\n",
       "      <td>0.005190</td>\n",
       "      <td>0.008010</td>\n",
       "      <td>0.014288</td>\n",
       "      <td>0.018384</td>\n",
       "      <td>0.003024</td>\n",
       "      <td>0.009549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1033_TIE_NEU_XX</td>\n",
       "      <td>1033</td>\n",
       "      <td>NEU</td>\n",
       "      <td>TIE</td>\n",
       "      <td>31</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Not Hispanic</td>\n",
       "      <td>0.095550</td>\n",
       "      <td>0.006244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026957</td>\n",
       "      <td>0.022260</td>\n",
       "      <td>0.016414</td>\n",
       "      <td>0.016756</td>\n",
       "      <td>0.006733</td>\n",
       "      <td>0.004914</td>\n",
       "      <td>0.014508</td>\n",
       "      <td>0.019974</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.008867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1016_ITH_ANG_XX</td>\n",
       "      <td>1016</td>\n",
       "      <td>ANG</td>\n",
       "      <td>ITH</td>\n",
       "      <td>61</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Not Hispanic</td>\n",
       "      <td>0.084617</td>\n",
       "      <td>0.012109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018824</td>\n",
       "      <td>0.015078</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>0.017400</td>\n",
       "      <td>0.006796</td>\n",
       "      <td>0.004869</td>\n",
       "      <td>0.017074</td>\n",
       "      <td>0.028463</td>\n",
       "      <td>0.006532</td>\n",
       "      <td>0.008469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1082_DFA_NEU_XX</td>\n",
       "      <td>1082</td>\n",
       "      <td>NEU</td>\n",
       "      <td>DFA</td>\n",
       "      <td>20</td>\n",
       "      <td>Female</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Not Hispanic</td>\n",
       "      <td>0.085034</td>\n",
       "      <td>0.006593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018890</td>\n",
       "      <td>0.013363</td>\n",
       "      <td>0.014448</td>\n",
       "      <td>0.019450</td>\n",
       "      <td>0.006658</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>0.021923</td>\n",
       "      <td>0.021861</td>\n",
       "      <td>0.006262</td>\n",
       "      <td>0.008800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1074_ITH_FEA_XX</td>\n",
       "      <td>1074</td>\n",
       "      <td>FEA</td>\n",
       "      <td>ITH</td>\n",
       "      <td>31</td>\n",
       "      <td>Female</td>\n",
       "      <td>African American</td>\n",
       "      <td>Not Hispanic</td>\n",
       "      <td>0.080987</td>\n",
       "      <td>0.009392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032367</td>\n",
       "      <td>0.019901</td>\n",
       "      <td>0.016781</td>\n",
       "      <td>0.019547</td>\n",
       "      <td>0.005369</td>\n",
       "      <td>0.006296</td>\n",
       "      <td>0.014283</td>\n",
       "      <td>0.020008</td>\n",
       "      <td>0.004862</td>\n",
       "      <td>0.008996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 144 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            FileID  ActorID Emotion SentenceID  Age     Sex              Race  \\\n",
       "0  1091_MTI_HAP_XX     1091     HAP        MTI   29  Female             Asian   \n",
       "1  1033_TIE_NEU_XX     1033     NEU        TIE   31    Male         Caucasian   \n",
       "2  1016_ITH_ANG_XX     1016     ANG        ITH   61    Male         Caucasian   \n",
       "3  1082_DFA_NEU_XX     1082     NEU        DFA   20  Female         Caucasian   \n",
       "4  1074_ITH_FEA_XX     1074     FEA        ITH   31  Female  African American   \n",
       "\n",
       "      Ethnicity  zcr_mean  energy_mean  ...  delta chroma_4_std  \\\n",
       "0  Not Hispanic  0.103094     0.010426  ...            0.017033   \n",
       "1  Not Hispanic  0.095550     0.006244  ...            0.026957   \n",
       "2  Not Hispanic  0.084617     0.012109  ...            0.018824   \n",
       "3  Not Hispanic  0.085034     0.006593  ...            0.018890   \n",
       "4  Not Hispanic  0.080987     0.009392  ...            0.032367   \n",
       "\n",
       "   delta chroma_5_std  delta chroma_6_std  delta chroma_7_std  \\\n",
       "0            0.016811            0.018297            0.020554   \n",
       "1            0.022260            0.016414            0.016756   \n",
       "2            0.015078            0.014390            0.017400   \n",
       "3            0.013363            0.014448            0.019450   \n",
       "4            0.019901            0.016781            0.019547   \n",
       "\n",
       "   delta chroma_8_std  delta chroma_9_std  delta chroma_10_std  \\\n",
       "0            0.005190            0.008010             0.014288   \n",
       "1            0.006733            0.004914             0.014508   \n",
       "2            0.006796            0.004869             0.017074   \n",
       "3            0.006658            0.007513             0.021923   \n",
       "4            0.005369            0.006296             0.014283   \n",
       "\n",
       "   delta chroma_11_std  delta chroma_12_std  delta chroma_std_std  \n",
       "0             0.018384             0.003024              0.009549  \n",
       "1             0.019974             0.003226              0.008867  \n",
       "2             0.028463             0.006532              0.008469  \n",
       "3             0.021861             0.006262              0.008800  \n",
       "4             0.020008             0.004862              0.008996  \n",
       "\n",
       "[5 rows x 144 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mid_data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d818c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the characteristics columns to mid_data_test:\n",
    "\n",
    "mid_data_test.insert(4, 'Age', age_list_test)\n",
    "mid_data_test.insert(5, 'Sex', sex_list_test)\n",
    "mid_data_test.insert(6, 'Race', race_list_test)\n",
    "mid_data_test.insert(7, 'Ethnicity', ethnicity_list_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b90cb4ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileID</th>\n",
       "      <th>ActorID</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>SentenceID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Race</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>energy_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>delta chroma_4_std</th>\n",
       "      <th>delta chroma_5_std</th>\n",
       "      <th>delta chroma_6_std</th>\n",
       "      <th>delta chroma_7_std</th>\n",
       "      <th>delta chroma_8_std</th>\n",
       "      <th>delta chroma_9_std</th>\n",
       "      <th>delta chroma_10_std</th>\n",
       "      <th>delta chroma_11_std</th>\n",
       "      <th>delta chroma_12_std</th>\n",
       "      <th>delta chroma_std_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1080_ITS_HAP_XX</td>\n",
       "      <td>1080</td>\n",
       "      <td>HAP</td>\n",
       "      <td>ITS</td>\n",
       "      <td>21</td>\n",
       "      <td>Male</td>\n",
       "      <td>African American</td>\n",
       "      <td>Not Hispanic</td>\n",
       "      <td>0.117958</td>\n",
       "      <td>0.017373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016764</td>\n",
       "      <td>0.014868</td>\n",
       "      <td>0.011382</td>\n",
       "      <td>0.019921</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.007523</td>\n",
       "      <td>0.016753</td>\n",
       "      <td>0.019980</td>\n",
       "      <td>0.006858</td>\n",
       "      <td>0.010857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1060_TAI_SAD_XX</td>\n",
       "      <td>1060</td>\n",
       "      <td>SAD</td>\n",
       "      <td>TAI</td>\n",
       "      <td>28</td>\n",
       "      <td>Female</td>\n",
       "      <td>African American</td>\n",
       "      <td>Not Hispanic</td>\n",
       "      <td>0.077414</td>\n",
       "      <td>0.014876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021449</td>\n",
       "      <td>0.018509</td>\n",
       "      <td>0.012929</td>\n",
       "      <td>0.038149</td>\n",
       "      <td>0.001742</td>\n",
       "      <td>0.002738</td>\n",
       "      <td>0.013408</td>\n",
       "      <td>0.017637</td>\n",
       "      <td>0.003253</td>\n",
       "      <td>0.010435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1006_IWW_FEA_XX</td>\n",
       "      <td>1006</td>\n",
       "      <td>FEA</td>\n",
       "      <td>IWW</td>\n",
       "      <td>58</td>\n",
       "      <td>Female</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Not Hispanic</td>\n",
       "      <td>0.054810</td>\n",
       "      <td>0.028619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019995</td>\n",
       "      <td>0.021226</td>\n",
       "      <td>0.019471</td>\n",
       "      <td>0.030409</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.004165</td>\n",
       "      <td>0.015450</td>\n",
       "      <td>0.014444</td>\n",
       "      <td>0.004704</td>\n",
       "      <td>0.009978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1089_ITS_ANG_XX</td>\n",
       "      <td>1089</td>\n",
       "      <td>ANG</td>\n",
       "      <td>ITS</td>\n",
       "      <td>24</td>\n",
       "      <td>Female</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Not Hispanic</td>\n",
       "      <td>0.073828</td>\n",
       "      <td>0.009950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022947</td>\n",
       "      <td>0.013466</td>\n",
       "      <td>0.011087</td>\n",
       "      <td>0.025880</td>\n",
       "      <td>0.009540</td>\n",
       "      <td>0.007164</td>\n",
       "      <td>0.022943</td>\n",
       "      <td>0.016025</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>0.011644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1049_TIE_HAP_XX</td>\n",
       "      <td>1049</td>\n",
       "      <td>HAP</td>\n",
       "      <td>TIE</td>\n",
       "      <td>25</td>\n",
       "      <td>Female</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>0.056212</td>\n",
       "      <td>0.020982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018491</td>\n",
       "      <td>0.014387</td>\n",
       "      <td>0.018956</td>\n",
       "      <td>0.029720</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.006317</td>\n",
       "      <td>0.015522</td>\n",
       "      <td>0.018624</td>\n",
       "      <td>0.006651</td>\n",
       "      <td>0.010669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 144 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            FileID  ActorID Emotion SentenceID  Age     Sex              Race  \\\n",
       "0  1080_ITS_HAP_XX     1080     HAP        ITS   21    Male  African American   \n",
       "1  1060_TAI_SAD_XX     1060     SAD        TAI   28  Female  African American   \n",
       "2  1006_IWW_FEA_XX     1006     FEA        IWW   58  Female         Caucasian   \n",
       "3  1089_ITS_ANG_XX     1089     ANG        ITS   24  Female         Caucasian   \n",
       "4  1049_TIE_HAP_XX     1049     HAP        TIE   25  Female         Caucasian   \n",
       "\n",
       "      Ethnicity  zcr_mean  energy_mean  ...  delta chroma_4_std  \\\n",
       "0  Not Hispanic  0.117958     0.017373  ...            0.016764   \n",
       "1  Not Hispanic  0.077414     0.014876  ...            0.021449   \n",
       "2  Not Hispanic  0.054810     0.028619  ...            0.019995   \n",
       "3  Not Hispanic  0.073828     0.009950  ...            0.022947   \n",
       "4      Hispanic  0.056212     0.020982  ...            0.018491   \n",
       "\n",
       "   delta chroma_5_std  delta chroma_6_std  delta chroma_7_std  \\\n",
       "0            0.014868            0.011382            0.019921   \n",
       "1            0.018509            0.012929            0.038149   \n",
       "2            0.021226            0.019471            0.030409   \n",
       "3            0.013466            0.011087            0.025880   \n",
       "4            0.014387            0.018956            0.029720   \n",
       "\n",
       "   delta chroma_8_std  delta chroma_9_std  delta chroma_10_std  \\\n",
       "0            0.000531            0.007523             0.016753   \n",
       "1            0.001742            0.002738             0.013408   \n",
       "2            0.000866            0.004165             0.015450   \n",
       "3            0.009540            0.007164             0.022943   \n",
       "4            0.002229            0.006317             0.015522   \n",
       "\n",
       "   delta chroma_11_std  delta chroma_12_std  delta chroma_std_std  \n",
       "0             0.019980             0.006858              0.010857  \n",
       "1             0.017637             0.003253              0.010435  \n",
       "2             0.014444             0.004704              0.009978  \n",
       "3             0.016025             0.005784              0.011644  \n",
       "4             0.018624             0.006651              0.010669  \n",
       "\n",
       "[5 rows x 144 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mid_data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c45af7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the files to csv\n",
    "\n",
    "mid_data_train.to_csv('midFeaturesTrainSetWithChars.csv', index=False)\n",
    "mid_data_test.to_csv('midFeaturesTestSetWithChars.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952f0401",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
