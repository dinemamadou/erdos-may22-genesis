{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03adb0e3",
   "metadata": {},
   "source": [
    "# Extract short term features\n",
    "This script extracted the short term features from the audio files. Since each clip has a different length, we thought of padding the shorter audios to have a uniform lenght.\n",
    "\n",
    "This idea has a couple of problems, mainly the fact that we're increasing the dimension of the dataset by adding just empty information. We never came back to this idea, but we keep it for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30040bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyAudioAnalysis import ShortTermFeatures as aF\n",
    "from pyAudioAnalysis import audioBasicIO as aIO \n",
    "import numpy as np \n",
    "import plotly.graph_objs as go \n",
    "import plotly\n",
    "import IPython\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "files = os.listdir('../Data/Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfa8bb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_time(seconds):\n",
    "    if seconds <= 60:\n",
    "        print('Duration: %f (s)' %seconds)\n",
    "    elif 60 < seconds <= 3600:\n",
    "        print('Duration: %f (min)' %(seconds/60))\n",
    "    else:\n",
    "        print('Duration: %f (h)' %(seconds/3600))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08f8eee",
   "metadata": {},
   "source": [
    "Load files and pad them to the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf4d5044",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 4.402534 (s)\n",
      "Number of files: 7442\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "# Load audio files and calculate the longest length\n",
    "Fs = []\n",
    "Signals = []\n",
    "max_length = 0\n",
    "for file in files:\n",
    "    fs, s = aIO.read_audio_file('../../AudioWAV/%s' %file)\n",
    "    Fs.append(fs)\n",
    "    Signals.append(s)\n",
    "    max_length = max(max_length, len(s))\n",
    "\n",
    "# Pad all files so that they all have the same length\n",
    "for i in range(len(files)):\n",
    "    s = Signals[i]\n",
    "    \n",
    "    before = 0\n",
    "    after  = max_length - len(s)\n",
    "    s_pad = np.pad(s, (before,after), mode='constant', constant_values=(0,0))\n",
    "    \n",
    "    Signals[i] = s_pad\n",
    "Signals = np.array(Signals)\n",
    "\n",
    "time_end = time.time()\n",
    "display_time(time_end-time_start)\n",
    "\n",
    "print('Number of files: %i' %(len(files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fadeed",
   "metadata": {},
   "source": [
    "Extract features from all audio clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ac466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "# Extract features from the first clip to get sizes\n",
    "win, step = 0.05, 0.025\n",
    "s = Signals[0,:]\n",
    "fs = Fs[0]\n",
    "[f, fn] = aF.feature_extraction(s, fs, int(fs * win), int(fs * step))\n",
    "\n",
    "Features = np.zeros((len(files), f.shape[0], f.shape[1]))\n",
    "Features[0,:,:] = f\n",
    "\n",
    "for i in range(1, len(files)):\n",
    "    s = Signals[i,:]\n",
    "    fs = Fs[i]\n",
    "    [f, fn] = aF.feature_extraction(s, fs, int(fs * win), int(fs * step))\n",
    "    \n",
    "    Features[i,:,:] = f\n",
    "\n",
    "time_end = time.time()\n",
    "display_time(time_end-time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "503b3350",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('Signals', Signals=Signals, Fs=Fs)\n",
    "np.savez('Features', win=win, step=step, Features=Features, fn=fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b5300fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7442, 68, 200)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e431a274",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
