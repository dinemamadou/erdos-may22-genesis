{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2992035",
   "metadata": {},
   "source": [
    "# Testing the pyAudioAnalysis module\n",
    "We used this file to explore the functions available in `pyAudioAnalysis`. We didn't save or use the results in this file in any other place. It is here purely for reference and exploration of the module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91921bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyAudioAnalysis import ShortTermFeatures as aF\n",
    "from pyAudioAnalysis import audioBasicIO as aIO \n",
    "import numpy as np \n",
    "import plotly.graph_objs as go \n",
    "import plotly\n",
    "import IPython\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4523d1cb",
   "metadata": {},
   "source": [
    "Load a couple of files. Here we are looking at the duration of the clips and the size of the arrays `s1` and `s2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c569b306",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs1, s1 = aIO.read_audio_file('../Data/Train/1001_DFA_SAD_XX.wav')\n",
    "print(fs1)\n",
    "print(s1.shape)\n",
    "\n",
    "# print duration in seconds:\n",
    "duration = len(s1) / float(fs1)\n",
    "print(f'duration = {duration} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8675b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs2, s2 = aIO.read_audio_file('../Data/Train/1002_IEO_SAD_LO.wav')\n",
    "print(fs2)\n",
    "print(s2.shape)\n",
    "\n",
    "# print duration in seconds:\n",
    "duration = len(s2) / float(fs2)\n",
    "print(f'duration = {duration} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f2fc6c",
   "metadata": {},
   "source": [
    "Since `s2` is longer than `s1`, we add enough zeros to `s1` to match the length of `s2`.\n",
    "\n",
    "**We might change this step depending on future analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cbbb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "before=0\n",
    "after=len(s2)-len(s1)\n",
    "s1_pad = np.pad(s1, (before,after), mode='constant', constant_values=(0,0))\n",
    "\n",
    "print(s1_pad.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1022a34",
   "metadata": {},
   "source": [
    "Listen to the audio with extra zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c252fd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(data=s1_pad, rate=fs1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb88c42",
   "metadata": {},
   "source": [
    "Listen to the original audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d128ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.display(IPython.display.Audio('AudioWAV/1001_DFA_SAD_XX.wav'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3a1630",
   "metadata": {},
   "source": [
    "Note: It seems that the volume of the original audio is lower."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2069aba",
   "metadata": {},
   "source": [
    "### Short term features\n",
    "Use pyAudioAnalysis to extract features from the sounds. Pay attention to the number of frames obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c425e417",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract short-term features using a 50msec non-overlapping windows\n",
    "win, step = 0.025, 0.025\n",
    "[f, fn] = aF.feature_extraction(s, fs, int(fs * win), \n",
    "                                int(fs * step))\n",
    "print(f'{f.shape[1]} frames, {f.shape[0]} short-term features')\n",
    "print('Feature names:')\n",
    "for i, nam in enumerate(fn):\n",
    "    print(f'{i}:{nam}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87700bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot short-term energy\n",
    "# create time axis in seconds\n",
    "time = np.arange(0, duration - step, win) \n",
    "# get the feature whose name is 'energy'\n",
    "energy = f[fn.index('energy'), :]\n",
    "mylayout = go.Layout(yaxis=dict(title=\"frame energy value\"),\n",
    "                     xaxis=dict(title=\"time (sec)\"))\n",
    "plotly.offline.iplot(go.Figure(data=[go.Scatter(x=time, \n",
    "                                                y=energy)], \n",
    "                               layout=mylayout))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5a82ff",
   "metadata": {},
   "source": [
    "## Explore more\n",
    "I got the above code from https://hackernoon.com/intro-to-audio-analysis-recognizing-sounds-using-machine-learning-qy2r3ufl. In this section, I want to understand the data types that the functions return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3aa204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract short-term features using a 50msec non-overlapping windows\n",
    "win, step = 0.050, 0.050\n",
    "win_t = int(fs*win)\n",
    "step_t = int(fs*step)\n",
    "\n",
    "print('fs = %f' %fs)\n",
    "print('win_t = %i' %win_t)\n",
    "print('step_t = %i' %step_t)\n",
    "\n",
    "[f, fn] = aF.feature_extraction(s, fs, int(fs * win), \n",
    "                                int(fs * step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0605a15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('fn')\n",
    "print(type(fn))\n",
    "print(len(fn))\n",
    "\n",
    "print('f')\n",
    "print(type(f))\n",
    "print(f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0375d541",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_idx = fn.index('energy')\n",
    "plt.plot(time, f[e_idx,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99f3fe5",
   "metadata": {},
   "source": [
    "## Another clip\n",
    "The above works as I expected. aF.feature_extraction gives me a matrix with 68 features and varying number of steps. I'm still not sure where the number of steps came from, but everything else makes sense. Now I'll try another clip -- possibly with a different duration -- and see if I get a 68-by-40 matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b4dc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs, s = aIO.read_audio_file('AudioWAV/1002_IEO_HAP_HI.wav')\n",
    "IPython.display.display(IPython.display.Audio('AudioWAV/1002_IEO_HAP_HI.wav'))\n",
    "\n",
    "# print duration in seconds:\n",
    "duration = len(s) / float(fs)\n",
    "print(f'duration = {duration} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acb1779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract short-term features using a 50msec non-overlapping windows\n",
    "win, step = 0.025, 0.025\n",
    "[f, fn] = aF.feature_extraction(s, fs, int(fs * win), \n",
    "                                int(fs * step))\n",
    "print(f'{f.shape[1]} frames, {f.shape[0]} short-term features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe352a6",
   "metadata": {},
   "source": [
    "No, in this new clip, I get 100 frames instead of 80."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db42506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot short-term energy\n",
    "# create time axis in seconds\n",
    "time = np.arange(0, duration - step, win) \n",
    "# get the feature whose name is 'energy'\n",
    "energy = f[fn.index('energy'), :]\n",
    "mylayout = go.Layout(yaxis=dict(title=\"frame energy value\"),\n",
    "                     xaxis=dict(title=\"time (sec)\"))\n",
    "plotly.offline.iplot(go.Figure(data=[go.Scatter(x=time, \n",
    "                                                y=energy)], \n",
    "                               layout=mylayout))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47946f4",
   "metadata": {},
   "source": [
    "## Different lengths...\n",
    "Ok, so different clips give matrices with different sizes. Ok, now I'll import a small batch (10, 50, 100?) and see how long it takes to get features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2391708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from os import listdir\n",
    "\n",
    "files = listdir('AudioWAV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be477fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = []\n",
    "signals = []\n",
    "features = []\n",
    "\n",
    "win, step = 0.050, 0.050\n",
    "time_start = time()\n",
    "for i in range(500):\n",
    "    filename = files[i]\n",
    "    \n",
    "    fs, s = aIO.read_audio_file('../../CREMA-D/AudioWAV/%s' %filename)\n",
    "    [f, fn] = aF.feature_extraction(s, fs, int(fs * win), int(fs * step))\n",
    "    \n",
    "    freqs.append(fs)\n",
    "    signals.append(s)\n",
    "    features.append(f)\n",
    "\n",
    "time_end = time()\n",
    "time_total = time_end-time_start\n",
    "\n",
    "if time_total <= 60:\n",
    "    print('Duration: %f (s)' %time_total)\n",
    "elif 60 < time_total <= 3600:\n",
    "    print('Duration: %f (min)' %(time_total/60))\n",
    "else:\n",
    "    print('Duration: %f (h)' %(time_total/3600))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f6a5fa",
   "metadata": {},
   "source": [
    "Note: Duration per number of files\n",
    "- 10 files: 0.411219 (s)\n",
    "- 100 files: 5.666346 (s)\n",
    "- 500 files: 28.749217 (s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcffd9e",
   "metadata": {},
   "source": [
    "## Actor distribution\n",
    "Here I create a dataframe with the actor code, the sentence spoken, the emotion conveyed, and the intensity in each clip. I'll dump it in a .csv file so that we don't need to do this again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bcc8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3c3fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('AudioWAV')\n",
    "\n",
    "time_start = time.time()\n",
    "df = pd.DataFrame(columns = ['actor', 'sentence', 'emotion', 'intensity'])\n",
    "for file in files:\n",
    "    cats = file.split('.')[0].split('_')\n",
    "    cats = pd.DataFrame([cats],\n",
    "                        columns = ['actor', 'sentence', 'emotion', 'intensity'])\n",
    "    df = pd.concat((df,cats), axis=0)\n",
    "\n",
    "time_end = time.time()\n",
    "time_total = time_end-time_start\n",
    "print('Number of files: %i' %(len(files)))\n",
    "if time_total <= 60:\n",
    "    print('Duration: %f (s)' %time_total)\n",
    "elif 60 < time_total <= 3600:\n",
    "    print('Duration: %f (min)' %(time_total/60))\n",
    "else:\n",
    "    print('Duration: %f (h)' %(time_total/3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9fdfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Categories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f58aeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127304a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Actors:')\n",
    "print(np.unique(df.sentence))\n",
    "print()\n",
    "print('Emotions:')\n",
    "print(np.unique(df.emotion))\n",
    "print()\n",
    "print('Intensities:')\n",
    "print(np.unique(df.intensity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1592ffaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.sum((df.intensity=='X')*1))\n",
    "print(np.sum((df.intensity=='XX')*1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73472d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "91*11*6+91*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142cbab6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
