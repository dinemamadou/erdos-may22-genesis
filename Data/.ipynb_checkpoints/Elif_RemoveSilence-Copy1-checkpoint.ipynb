{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from pyAudioAnalysis import audioBasicIO as aIO;\n",
    "from pyAudioAnalysis import audioSegmentation as aS;\n",
    "from pydub import AudioSegment;\n",
    "from pydub.silence import split_on_silence;\n",
    "import os;\n",
    "import pandas as pd;\n",
    "import numpy as np;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new folders for the clips with removed silence\n",
    "if not os.path.isdir('../Data/Train_no_silence'):\n",
    "    os.mkdir('../Data/Train_NoSilence')\n",
    "    \n",
    "if not os.path.isdir('../Data/Test_no_silence'):\n",
    "    os.mkdir('../Data/Test_NoSilence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all the files from the training set\n",
    "files_train = os.listdir('Train')\n",
    "files_test = os.listdir('Test')\n",
    "\n",
    "# sorting the files by name\n",
    "files_train.sort()\n",
    "files_test.sort()\n",
    "\n",
    "\n",
    "# I'm using MacOS, and it by default has this .DS_store file, which I can't get rid of. \n",
    "# It's the first file in the folder.\n",
    "# That's why I'm removing it. If you are using this code in your own PC, this might not apply to you.\n",
    "# in that case, comment out the del function line.\n",
    "del files_train[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add path name to the file name\n",
    "fnames_train = []\n",
    "fnames_test  = []\n",
    "for i in range(len(files_train)):\n",
    "    fname = \"Train/%s\" % files_train[i]\n",
    "    fnames_train.append(fname)\n",
    "    \n",
    "for i in range(len(files_test)):\n",
    "    fname = \"Test/%s\" % files_test[i]\n",
    "    fnames_test.append(fname)\n",
    "\n",
    "# sort the list of file names with path     \n",
    "fnames_train.sort()\n",
    "fnames_test.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Fs, signal = aIO.read_audio_file(fnames_train[9])\n",
    "segments = aS.silence_removal(signal, Fs, 0.020, 0.020, smooth_window = 0.4, weight = 0.4, plot = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_mSec(segments):\n",
    "    \n",
    "    if len(segments)==1:\n",
    "        segments[0][0]=segments[0][0]*1000\n",
    "        segments[0][1]=segments[0][1]*1000\n",
    "    elif len(segments)==2:\n",
    "        segments[0][0]=segments[0][0]*1000\n",
    "        segments[0][1]=segments[0][1]*1000\n",
    "        segments[1][0]=segments[1][0]*1000\n",
    "        segments[1][1]=segments[1][1]*1000\n",
    "    elif len(segments)==3:\n",
    "        segments[0][0]=segments[0][0]*1000\n",
    "        segments[0][1]=segments[0][1]*1000\n",
    "        segments[1][0]=segments[1][0]*1000\n",
    "        segments[1][1]=segments[1][1]*1000\n",
    "        segments[2][0]=segments[2][0]*1000\n",
    "        segments[2][1]=segments[2][1]*1000\n",
    "    \n",
    "    return segments;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = turn_mSec(segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound = AudioSegment.from_file(fnames_train[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combine_slices(segments, sound):\n",
    "\n",
    "    if len(segments)==1:\n",
    "        slice1 = sound[segments[0][0]:segments[0][1]]\n",
    "        final_sound = slice1\n",
    "    elif len(segments)==2:\n",
    "        slice1 = sound[segments[0][0]:segments[0][1]]\n",
    "        slice2 = sound[segments[1][0]:segments[1][1]]\n",
    "        final_sound = slice1+slice2\n",
    "    elif len(segments)==3:\n",
    "        slice1 = sound[segments[0][0]:segments[0][1]]\n",
    "        slice2 = sound[segments[1][0]:segments[1][1]]\n",
    "        slice3 = sound[segments[2][0]:segments[2][1]]\n",
    "        final_sound = slice1+slice2+slice3\n",
    "\n",
    "    return final_sound\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defined a function here but for some reason it kept on throwing errors. \n",
    "# instead, I \n",
    "\n",
    "def remove_silence(filename_wpath, filename, path_folder):\n",
    "    Fs, signal = aIO.read_audio_file('filename_wpath');\n",
    "    segments = aS.silence_removal(signal, Fs, 0.020, 0.020, smooth_window = 0.4, weight = 0.4, plot = False);\n",
    "    \n",
    "    segments = turn_mSec(segments);\n",
    "    sound = AudioSegment.from_file('filename_wpath');\n",
    "    final_sound = get_combine_slices(segments, sound);\n",
    "    \n",
    "    new_fname_path = path_folder + filename\n",
    "    output_file = \"new_fname_path.wav\"\n",
    "    print(\"Exporting file\", output_file)\n",
    "    finalsound.export(output_file, format=\"wav\")\n",
    "    \n",
    "    old_dur = sound.duration_seconds\n",
    "    new_dur = finalsound.duration_seconds\n",
    "    \n",
    "    return old_dur, new_dur;\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalS = get_combine_slices(segments, sound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sound.duration_seconds)\n",
    "print(finalS.duration_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x , y = remove_silence(fnames_train[5], files_train[5], pathname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing silence for Train data\n",
    "\n",
    "\n",
    "pathname = \"Train_NoSilence/\";\n",
    "oldDur = [];\n",
    "newDur = [];\n",
    "\n",
    "\n",
    "for i in np.arange(0,len(fnames_train),1):\n",
    "    print(i)\n",
    "    t1, t2 = remove_silence(fnames_train[i], files_train[i], pathname);\n",
    "    oldDur.append(t1);\n",
    "    newDur.append(t2);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting file Train_NoSilence/1001_DFA_ANG_XX.wav.wav\n",
      "Exporting file Train_NoSilence/1001_DFA_DIS_XX.wav.wav\n",
      "Exporting file Train_NoSilence/1001_DFA_FEA_XX.wav.wav\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "pathname = \"Train_NoSilence/\";\n",
    "oldDur = [];\n",
    "newDur = [];\n",
    "\n",
    "\n",
    "for i in np.arange(0,len(fnames_train,1):    \n",
    "    Fs, signal = aIO.read_audio_file(fnames_train[i]);\n",
    "    segments = aS.silence_removal(signal, Fs, 0.020, 0.020, smooth_window = 0.4, weight = 0.4, plot = False);\n",
    "    \n",
    "    segments = turn_mSec(segments);\n",
    "    sound = AudioSegment.from_file(fnames_train[i]);\n",
    "    final_sound = get_combine_slices(segments, sound);\n",
    "    \n",
    "    new_fname_path = pathname + files_train[i]\n",
    "    output_file = \"{}.wav\".format(new_fname_path)\n",
    "    print(\"Exporting file\", output_file)\n",
    "    final_sound.export(output_file, format=\"wav\")\n",
    "    \n",
    "    old_dur = sound.duration_seconds\n",
    "    new_dur = final_sound.duration_seconds\n",
    "    \n",
    "    oldDur.append(old_dur);\n",
    "    newDur.append(new_dur);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.2755625, 2.3356875, 2.1688125]\n",
      "[1.44, 1.18, 0.92]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing silence for Test data\n",
    "pathname_t = \"Test_NoSilence/\";\n",
    "oldDur_Test = [];\n",
    "newDur_Test = [];\n",
    "\n",
    "# Note the index starts from 0 in this loop, because there's no .DS_store file in this folder.\n",
    "for i in np.arange(0,len(fnames_test),1):\n",
    "    print(i)\n",
    "    t1, t2 = remove_silence(fnames_test[i], files_test[i], pathname_t);\n",
    "    oldDur_Test.append(t1);\n",
    "    newDur_Test.append(t2);    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(columns = ['FileID', 'ActorID', 'SentenceID', 'Emotion', 'Intensity'])\n",
    "\n",
    "for file in files_train:\n",
    "    fileID = file.split('.')[0]\n",
    "    cats = fileID.split('_')\n",
    "    \n",
    "    new_row = pd.DataFrame([[fileID] + cats],\n",
    "                           columns = ['FileID', 'ActorID', 'SentenceID', 'Emotion', 'Intensity'])\n",
    "    df_train = pd.concat((df_train,new_row), axis=0, ignore_index=True)\n",
    "\n",
    "# Turn columns into factors (except for FileID)\n",
    "for col in df_train.columns:\n",
    "    if col != 'FileID':\n",
    "        df_train[col] = (df_train[col]).astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Old_Dur'] = oldDur\n",
    "df_train['New_Dur'] = newDur\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_test = pd.DataFrame(columns = ['FileID', 'ActorID', 'SentenceID', 'Emotion', 'Intensity'])\n",
    "\n",
    "for file in files_test:\n",
    "    fileID = file.split('.')[0]\n",
    "    cats = fileID.split('_')\n",
    "    \n",
    "    new_row = pd.DataFrame([[fileID] + cats],\n",
    "                        columns = ['FileID', 'ActorID', 'SentenceID', 'Emotion', 'Intensity'])\n",
    "    df_test = pd.concat((df_test,new_row), axis=0, ignore_index=True)\n",
    "\n",
    "# Turn columns into factors (except for FileID)\n",
    "for col in df_test.columns:\n",
    "    if col != 'FileID':\n",
    "        df_test[col] = (df_test[col]).astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# filename_wpath = fnames_train OR fnames_test ;\n",
    "# filename = files_train OR files_test;\n",
    "# path_folder = \"Train_NoSilence\" OR \"Test_NoSilence\"\n",
    "\n",
    "def remove_silence(filename_wpath, filename, path_folder, min_silence_len=500, silence_thresh=-40):\n",
    "    \n",
    "    \n",
    "    [Fs, x] = aIO.read_audio_file('filename_wpath')\n",
    "    segments = aS.silence_removal(x, Fs, 0.020, 0.020, smooth_window = 0.4, weight = 0.4, plot = False)\n",
    "    \n",
    "    # Read in the sound file from folder\n",
    "    sound = AudioSegment.from_file(filename_wpath)\n",
    "    old_dur = sound.duration_seconds\n",
    "    # Divide into chunks, which removes the silences\n",
    "    audio_chunks = split_on_silence(sound, min_silence_len, silence_thresh)\n",
    "    \n",
    "    # Combine the divided chunks together to have single, silence-removed sound file\n",
    "    new_fname_path = path_folder + filename\n",
    "    for i, chunk in enumerate(audio_chunks):\n",
    "       output_file = new_fname_path.format(i)\n",
    "       print(\"Exporting file\", output_file)\n",
    "       chunk.export(output_file, format=\"wav\")\n",
    "    \n",
    "    newsound = AudioSegment.from_file(new_fname_path)\n",
    "    new_dur = newsound.duration_seconds\n",
    "    \n",
    "    return old_dur, new_dur"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
