{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dda29221",
   "metadata": {},
   "source": [
    "In this notebook, we apply our final CNN model to the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca1592aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, shutil\n",
    "\n",
    "## For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from seaborn import set_style\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "## This sets the plot style\n",
    "## to have a grid on a white background\n",
    "set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80e19bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the things we need from keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#from keras.utils import \n",
    "# tf.keras.utils.image_dataset_from_directory\n",
    "\n",
    "# New: this will save the training history to a csv file:\n",
    "from keras.callbacks import CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c6ac0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the shape of the images to be loaded into the model:\n",
    "\n",
    "pixel_height = 219     # This is the FIRST coordinate in the files\n",
    "pixel_width = 269      # This is the SECOND coordinate in the files\n",
    "channels = 3           # 3 because we're using RGB\n",
    "\n",
    "\n",
    "# Type in the paths to the train, validation, and test directories here:\n",
    "\n",
    "# train_dir = 'spectrograms_cnn_base/large_train' # we no longer use a validation set\n",
    "test_dir = '../Data/spectrograms_cnn_base/test'\n",
    "#validation_dir = 'spectrograms_cnn_base/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65bdcf3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-04 10:59:01.371121: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Import the final model:\n",
    "\n",
    "model = models.load_model('Final_model_trained/pathname_model_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "875e2a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1200 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create a generator that will import and preprocess the spectrograms in the test folder: \n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)  # rescale so values are between 0 and 1\n",
    "\n",
    "\n",
    "batch_size = 1200 #Same as the number of images in the test set. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "                    test_dir,\n",
    "                    target_size = (pixel_height, pixel_width),\n",
    "                    batch_size = batch_size,\n",
    "                    class_mode = 'categorical')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8540523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the output of test_generator:\n",
    "\n",
    "output = test_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcec6859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide output into X_test, y_test:\n",
    "\n",
    "X_test = output[0]\n",
    "y_test = output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6742745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 13s 322ms/step\n"
     ]
    }
   ],
   "source": [
    "# Get the predicted values on X_test, turn them to integers from 0 to 5:\n",
    "\n",
    "pred = np.argmax(model.predict(X_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57c7b1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the one-hot encodings in y_test into integers from 0 to 5:\n",
    "\n",
    "y_test_cats = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b37c7dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ANG': 0, 'DIS': 1, 'FEA': 2, 'HAP': 3, 'NEU': 4, 'SAD': 5}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the mapping between integers to emotion labels:\n",
    "\n",
    "test_generator.class_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9aac821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dict with int to emotion label:\n",
    "\n",
    "dict = {0:'ANG', 1:'DIS', 2:'FEA', 3:'HAP', 4:'NEU', 5:'SAD'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af6a6a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get copies of pred, y_test_cats with the emotional labels:\n",
    "\n",
    "pred_list = list(pred)\n",
    "\n",
    "y_test_cats_list = list(y_test_cats)\n",
    "\n",
    "\n",
    "pred_list_emos = [dict[num] for num in pred_list]\n",
    "\n",
    "\n",
    "y_test_cats_emos = [dict[num] for num in y_test_cats_list]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "091c53ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 87   1  40  74   4   9]\n",
      " [ 15 133  45   1   0   3]\n",
      " [ 29  41 101  13   8   5]\n",
      " [ 18   3  19 135   8  14]\n",
      " [ 19  11  77  62  19   9]\n",
      " [ 23  28  38  67   2  39]]\n"
     ]
    }
   ],
   "source": [
    "# Get the confusion matrix, with labels in the same order as the confusion matrix for SVM:\n",
    "labels = ['NEU', 'ANG', 'HAP', 'SAD', 'FEA', 'DIS']\n",
    "\n",
    "conf_mat = confusion_matrix(y_test_cats_emos, pred_list_emos, labels=labels )\n",
    "\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b44f1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42833333333333334\n"
     ]
    }
   ],
   "source": [
    "# Get the overall accuracy:\n",
    "acc = accuracy_score(y_test_cats_emos, pred_list_emos)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4947cdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redraw the confusion matrix to have emotion labels on the axes:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
